{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"You Can't Be Serious\" - Detecting Sarcasm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As requested, below is the code and techniques employed to develop an algorithm to sort out sarcastic headlines from non-sarcastic ones. To get started, let's import the libraries necessary to make the magic happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ALEJA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ALEJA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ALEJA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly import tools\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the libraries on hand, let's now grab our data and see what we are working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "      <td>theonion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "      <td>huffingtonpost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "      <td>huffingtonpost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "      <td>theonion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "      <td>theonion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28614</th>\n",
       "      <td>1</td>\n",
       "      <td>jews to celebrate rosh hashasha or something</td>\n",
       "      <td>https://www.theonion.com/jews-to-celebrate-ros...</td>\n",
       "      <td>theonion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28615</th>\n",
       "      <td>1</td>\n",
       "      <td>internal affairs investigator disappointed con...</td>\n",
       "      <td>https://local.theonion.com/internal-affairs-in...</td>\n",
       "      <td>theonion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28616</th>\n",
       "      <td>0</td>\n",
       "      <td>the most beautiful acceptance speech this week...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/andrew-ah...</td>\n",
       "      <td>huffingtonpost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28617</th>\n",
       "      <td>1</td>\n",
       "      <td>mars probe destroyed by orbiting spielberg-gat...</td>\n",
       "      <td>https://www.theonion.com/mars-probe-destroyed-...</td>\n",
       "      <td>theonion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28618</th>\n",
       "      <td>1</td>\n",
       "      <td>dad clarifies this not a food stop</td>\n",
       "      <td>https://www.theonion.com/dad-clarifies-this-no...</td>\n",
       "      <td>theonion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28619 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_sarcastic                                           headline  \\\n",
       "0                 1  thirtysomething scientists unveil doomsday clo...   \n",
       "1                 0  dem rep. totally nails why congress is falling...   \n",
       "2                 0  eat your veggies: 9 deliciously different recipes   \n",
       "3                 1  inclement weather prevents liar from getting t...   \n",
       "4                 1  mother comes pretty close to using word 'strea...   \n",
       "...             ...                                                ...   \n",
       "28614             1       jews to celebrate rosh hashasha or something   \n",
       "28615             1  internal affairs investigator disappointed con...   \n",
       "28616             0  the most beautiful acceptance speech this week...   \n",
       "28617             1  mars probe destroyed by orbiting spielberg-gat...   \n",
       "28618             1                 dad clarifies this not a food stop   \n",
       "\n",
       "                                            article_link          source  \n",
       "0      https://www.theonion.com/thirtysomething-scien...        theonion  \n",
       "1      https://www.huffingtonpost.com/entry/donna-edw...  huffingtonpost  \n",
       "2      https://www.huffingtonpost.com/entry/eat-your-...  huffingtonpost  \n",
       "3      https://local.theonion.com/inclement-weather-p...        theonion  \n",
       "4      https://www.theonion.com/mother-comes-pretty-c...        theonion  \n",
       "...                                                  ...             ...  \n",
       "28614  https://www.theonion.com/jews-to-celebrate-ros...        theonion  \n",
       "28615  https://local.theonion.com/internal-affairs-in...        theonion  \n",
       "28616  https://www.huffingtonpost.com/entry/andrew-ah...  huffingtonpost  \n",
       "28617  https://www.theonion.com/mars-probe-destroyed-...        theonion  \n",
       "28618  https://www.theonion.com/dad-clarifies-this-no...        theonion  \n",
       "\n",
       "[28619 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('./Sarcasm_Headlines_Dataset_v2.json',lines=True)\n",
    "data[\"source\"] = data[\"article_link\"].apply(lambda x: re.findall(r'\\w+', x)[2])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per above, our data consists of four variables; three of which are feature vectors and one acting as the response. Upon inspection we can see how we really just need to concern ourselves with two columns only: \"is_sarcastic\" and \"headline\".\n",
    "\n",
    "The problem now is determining whether an article is satire in nature or not according the the phrasing of its headline. As humans, we intuitively pick up on such nuances. However, how can we program such intuition to a machine?\n",
    "\n",
    "We can begin by creating a form of \"database\" conveying the frequency, and in extension relevance, of the words present in our headlines and attempt to correlate this information to the labels in question (sarcastic, non-sarcastic). We will accomplish this via a method we will refer to as a \"bag of words\".\n",
    "\n",
    "Our \"bag of words\" data preparation entails the following steps:\n",
    "\n",
    "- 1) Tokenizing each headline\n",
    "- 2) Removing \"stopwords\" - Words conveying no meaning or insights (eg. \"of\", \"the\", \"for\", \"in\", etc.)\n",
    "- 3) Stemming - Reducing words to their base level as to capture the essence of a word in order to later compare accurately (eg. \"running\", \"ran\", and \"run\" should all be deemed as the same term)\n",
    "- 4) Capturing the frequency of each word per document for all the documents in the dataframe\n",
    "- 5) Assign Term Frequency - Inverse Document Frequency (TFIDF) scores to each term per document. A TFIDF score reflects the uniqueness of a word against the entire body of documents considered. In a nutshell, the score increases by every occurrence in the document in question but is decreased by every occurrence across all documents. Thus capturing the uniqueness of the word to its document and not to the body of documents (filtering out common words as \"what\", \"when\", \"yes\",\"no\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a very reductive demonstration:\n",
    "\n",
    "## Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'merely', 'a', 'test', 'for', 'comprehension']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"This is merely a test for comprehension.\"\n",
    "example2 = re.sub('[^A-Za-z]', ' ', example.lower()) #regex used to remove punctuation and non alphabet characters\n",
    "token_example = word_tokenize(example2)\n",
    "token_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'merely', 'test', 'comprehension']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in token_example:\n",
    "    if word in stopwords.words(\"english\"):\n",
    "        token_example.remove(word)\n",
    "        \n",
    "token_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'mere', 'test', 'comprehens']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "for i in range(len(token_example)):\n",
    "    token_example[i] = stemmer.stem(token_example[i])\n",
    "    \n",
    "token_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing it together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is mere test comprehens'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_example = \" \".join(token_example)\n",
    "\n",
    "token_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the risk of being redundant, below is another demonstration of our \"bag of words\" approach, but in this case with a list of documents. We will conclude this demo by also calculating the \"TF-IDF\" scores for the words in question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['everyon', 'prove', 'sentenc', 'super', 'test', 'thi', 'to']\n",
      "[[1 0 0 1 1 1 0]\n",
      " [0 1 1 1 0 1 1]\n",
      " [0 0 0 1 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALEJA\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning:\n",
      "\n",
      "Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_document = []\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "documents = [\"This is a super test everyone.\",\"This other sentence is to prove a super.\",\" Super.\"]\n",
    "\n",
    "\n",
    "for document in list(documents): #Iterating through every document and removing non alphabet chars.\n",
    "    clean = re.sub('[^A-Za-z]', ' ', document)\n",
    "    tokenized_clean = word_tokenize(clean)\n",
    "\n",
    "    for word in tokenized_clean: #TOKENIZATION\n",
    "        if word in stopwords.words(\"english\"):\n",
    "            tokenized_clean.remove(word)\n",
    "\n",
    "    for i in range(len(tokenized_clean)):#STEMMING\n",
    "        tokenized_clean[i] = stemmer.stem(tokenized_clean[i])\n",
    "    \n",
    "    new_document.append(\" \".join(tokenized_clean))#BRINGING IT TOGETHER\n",
    "    \n",
    "vectorized_test = CountVectorizer(max_features=1000)#Capturing the frequencies of our words in a CountVectorizer object\n",
    "\n",
    "X_test = vectorized_test.fit_transform(new_document).toarray()#Building our matrix of frequencies\n",
    "print(vectorized_test.get_feature_names())\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how the \"super\" column has 1's all the way down since this word appears in every document.\n",
    "\n",
    "Let's calculate the TF-IDF now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58, 0.  , 0.  , 0.35, 0.58, 0.44, 0.  ],\n",
       "       [0.  , 0.5 , 0.5 , 0.3 , 0.  , 0.38, 0.5 ],\n",
       "       [0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "tfidf_X = tfidf.fit_transform(X_test).toarray()\n",
    "\n",
    "np.round(tfidf_X,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisiting our \"super\" column,the scores are .35, .3, and 1, respectively. This makes sense since the first two scores are the lowest in our matrix since \"super\" appears in all three documents. The third score of 1 is explained by the fact that it was the sole word in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equipped with our \"bag of words\" procedure, let's apply it to our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_headline = []\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "for headline in list(data.headline):\n",
    "    clean = re.sub('[^A-Za-z]', ' ', headline)\n",
    "    tokenized_clean = word_tokenize(clean)\n",
    "\n",
    "\n",
    "    for word in tokenized_clean:\n",
    "        if word in stopwords.words(\"english\"):\n",
    "            tokenized_clean.remove(word)\n",
    "\n",
    "    for i in range(len(tokenized_clean)):\n",
    "        tokenized_clean[i] = stemmer.stem(tokenized_clean[i])\n",
    "\n",
    "    new_headline.append(\" \".join(tokenized_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = CountVectorizer(max_features=1000)\n",
    "'''\n",
    "I am choosing to retain the top 1000 features with the most frequencies. Anything higher results in algorithms which take\n",
    "too long to run for almost no gain in insights. After testing \"max_features\" of 500, 5000, and 10000, I got virtually\n",
    "the same results with the higher parameters improving accuracy by 1 or two points. However, the 5000 parameter takes  \n",
    "over 2 hours to run and the 10000 option is, well, not an option; ran non stop overnight to no avail.\n",
    "\n",
    "'''\n",
    "\n",
    "X = matrix.fit_transform(new_headline).toarray()\n",
    "Y = data.is_sarcastic\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28619, 1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "tfidf_X = tfidf.fit_transform(X).toarray()\n",
    "tfidf_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the fun begins. Our TFIDF scores will take the place of the headline column in our algorithm training. This means we will be training our models using these scores to predict whether a headline is sarcastic or not. Before getting carried away, we will first split our data with a .7/.3 split and proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(7)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(tfidf_X,Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model we will be training and testing is a support vector machine(SVM). Two type of SVMs will be examined, a linear SVM and a radial basis function kerneled SVM. The models will assume a hard classifier with a margin cost parameter set at 1 (the default value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(7)\n",
    "\n",
    "svm_results = SVC(kernel = \"linear\").fit(X_train,Y_train.ravel()).predict(X_test)\n",
    "svm_results_kernel = SVC(kernel = \"rbf\").fit(X_train,Y_train.ravel()).predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for our linear SVM are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      4452\n",
      "           1       0.76      0.71      0.74      4134\n",
      "\n",
      "    accuracy                           0.75      8586\n",
      "   macro avg       0.75      0.75      0.75      8586\n",
      "weighted avg       0.75      0.75      0.75      8586\n",
      "\n",
      "Accuracy score: 0.7542511064523643\n",
      "Precision score: 0.7612287041817243\n",
      "Recall score: 0.7133526850507983\n",
      "F1 score: 0.7365134865134865\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,svm_results))\n",
    "print('Accuracy score: {}'.format(accuracy_score(Y_test, svm_results)))\n",
    "print('Precision score: {}'.format(precision_score(Y_test, svm_results)))\n",
    "print('Recall score: {}'.format(recall_score(Y_test, svm_results)))\n",
    "print('F1 score: {}'.format(f1_score(Y_test, svm_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas its kerneled counterparts results in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      4452\n",
      "           1       0.77      0.73      0.75      4134\n",
      "\n",
      "    accuracy                           0.76      8586\n",
      "   macro avg       0.76      0.76      0.76      8586\n",
      "weighted avg       0.76      0.76      0.76      8586\n",
      "\n",
      "Accuracy score: 0.7626368506871651\n",
      "Precision score: 0.768305171530978\n",
      "Recall score: 0.7259313014029996\n",
      "F1 score: 0.7465174129353233\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,svm_results_kernel))\n",
    "print('Accuracy score: {}'.format(accuracy_score(Y_test, svm_results_kernel)))\n",
    "print('Precision score: {}'.format(precision_score(Y_test, svm_results_kernel)))\n",
    "print('Recall score: {}'.format(recall_score(Y_test, svm_results_kernel)))\n",
    "print('F1 score: {}'.format(f1_score(Y_test, svm_results_kernel)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model we will train is a neural network. After many test runs a final model was decided on with rectified linear unit activation functions (\"ReLu\") for the nodes(aka. neurons) with 25 nodes in each of its 20 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(7)\n",
    "\n",
    "mlp = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=.9,\n",
    "       beta_2=.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(25, 20), learning_rate='constant',\n",
    "       learning_rate_init=0.01, max_iter=1000, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=False, warm_start=False)\n",
    "\n",
    "\n",
    "mlp.fit(X_train,Y_train.ravel())\n",
    "\n",
    "NN_predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73      4463\n",
      "           1       0.71      0.70      0.71      4123\n",
      "\n",
      "    accuracy                           0.72      8586\n",
      "   macro avg       0.72      0.72      0.72      8586\n",
      "weighted avg       0.72      0.72      0.72      8586\n",
      "\n",
      "Accuracy score: 0.7225716282320056\n",
      "Precision score: 0.7139346276726468\n",
      "Recall score: 0.7045840407470289\n",
      "F1 score: 0.7092285156249999\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,NN_predictions))\n",
    "print('Accuracy score: {}'.format(accuracy_score(Y_test, NN_predictions)))\n",
    "print('Precision score: {}'.format(precision_score(Y_test, NN_predictions)))\n",
    "print('Recall score: {}'.format(recall_score(Y_test, NN_predictions)))\n",
    "print('F1 score: {}'.format(f1_score(Y_test, NN_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, capturing the frequency of words across the body of documents provides us insight as to the relevance of a given word to its mother document. We can elaborate on this idea to predict whether a document is sarcastic or not based on the TF-IDF scores for all documents present. In theory, documents with similar TF-IDF scores for certain words may yield a means classification. \n",
    "\n",
    "Based on our results, all three models do a fair job classifying our articles; scoring in the 70's range of accuracy. Nevertheless, the kerneled SVM model proves to be the most accurate with an accuracy of 76%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
